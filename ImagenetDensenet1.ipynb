{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "0lhx1XzJ3CIy",
    "outputId": "2f24eaba-605f-43f2-ad14-64e17dcfefd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Cloning into 'keras-resnet'...\n",
      "remote: Enumerating objects: 126, done.\u001b[K\n",
      "remote: Total 126 (delta 0), reused 0 (delta 0), pack-reused 126\u001b[K\n",
      "Receiving objects: 100% (126/126), 1.65 MiB | 1.53 MiB/s, done.\n",
      "Resolving deltas: 100% (58/58), done.\n",
      "Collecting PyDrive\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e0/0e64788e5dd58ce2d6934549676243dc69d982f198524be9b99e9c2a4fd5/PyDrive-1.3.1.tar.gz (987kB)\n",
      "\u001b[K    100% |████████████████████████████████| 993kB 19.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.11.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
      "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.11.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.4)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
      "Building wheels for collected packages: PyDrive\n",
      "  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fa/d2/9a/d3b6b506c2da98289e5d417215ce34b696db856643bad779f4\n",
      "Successfully built PyDrive\n",
      "Installing collected packages: PyDrive\n",
      "Successfully installed PyDrive-1.3.1\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "!rm -rf tiny-imagenet-200.zip tiny-imagenet-200\n",
    "!git clone https://github.com/raghakot/keras-resnet.git\n",
    "!cp drive/'My Drive'/tiny-imagenet-200_flow.zip .\n",
    "!unzip -qq tiny-imagenet-200_flow.zip\n",
    "!rm -rf tiny-imagenet-200/val/images tiny-imagenet-200/val/val_annotations.txt\n",
    "!pip install PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zxrHu6fpFPI"
   },
   "outputs": [],
   "source": [
    "def drive_authenticate():\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)\n",
    "  return drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYefiC_L3LYf"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE, TRAINING_IMAGES_DIR, VAL_IMAGES_DIR = None, None, None\n",
    "model_file=\"Imagenetvd.hdf5\"  \n",
    "def set_image_size(image_size):\n",
    "  global IMAGE_SIZE, TRAINING_IMAGES_DIR, VAL_IMAGES_DIR\n",
    "  IMAGE_SIZE = image_size\n",
    "  if IMAGE_SIZE == 32:\n",
    "    TRAINING_IMAGES_DIR = 'tiny-imagenet-200-32/train/'\n",
    "    VAL_IMAGES_DIR = 'tiny-imagenet-200-32/val/'\n",
    "  else:\n",
    "    TRAINING_IMAGES_DIR = 'tiny-imagenet-200/train/'\n",
    "    VAL_IMAGES_DIR = 'tiny-imagenet-200/val/'\n",
    "set_image_size(64)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uY7EnC8b3otl",
    "outputId": "eb640b9a-a3ee-43ce-e46d-5aa545cf7f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n",
      "Found 10000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as k\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 200\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "NUM_IMAGES = NUM_CLASSES * NUM_IMAGES_PER_CLASS\n",
    "TRAIN_SIZE = NUM_IMAGES\n",
    "NUM_CHANNELS = 3\n",
    "NUM_VAL_IMAGES = 10000\n",
    "NUM_EPOCHS = 50\n",
    "IMAGE_SIZE_T = 48\n",
    "\n",
    "ia.seed(1)\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "# Define our sequence of augmentation steps that will be applied to every image.\n",
    "\n",
    "seq20 = iaa.Sequential(\n",
    "    [\n",
    "        #\n",
    "        # Apply the following augmenters to most images.\n",
    "        #\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "\n",
    "        # crop some of the images by 0-10% of their height/width\n",
    "        sometimes(iaa.Crop(percent=(0, 0.1))),\n",
    "\n",
    "        # Apply affine transformations to some of the images\n",
    "        # - scale to 80-120% of image height/width (each axis independently)\n",
    "        # - translate by -20 to +20 relative to height/width (per axis)\n",
    "        # - rotate by -45 to +45 degrees\n",
    "        # - shear by -16 to +16 degrees\n",
    "        # - order: use nearest neighbour or bilinear interpolation (fast)\n",
    "        # - mode: use any available mode to fill newly created pixels\n",
    "        #         see API or scikit-image for which modes are available\n",
    "        # - cval: if the mode is constant, then use a random brightness\n",
    "        #         for the newly created pixels (e.g. sometimes black,\n",
    "        #         sometimes white)\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "            rotate=(-10, 10),\n",
    "            shear=(-4, 4),\n",
    "            order=[0, 1],\n",
    "            cval=(0, 255),\n",
    "            mode=ia.ALL\n",
    "        )),\n",
    "\n",
    "        #\n",
    "        # Execute 0 to 5 of the following (less important) augmenters per\n",
    "        # image. Don't execute all of them, as that would often be way too\n",
    "        # strong.\n",
    "        #\n",
    "        iaa.SomeOf((0, 2),\n",
    "            [\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)),\n",
    "                    iaa.AverageBlur(k=(2, 7)),\n",
    "                ]),\n",
    "                iaa.AdditiveGaussianNoise(\n",
    "                    loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n",
    "                ),\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5),\n",
    "                    iaa.CoarseDropout(\n",
    "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                        per_channel=0.2\n",
    "                    ),\n",
    "                ]),\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05)))            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    # do all of the above augmentations in random order\n",
    "    random_order=True\n",
    ")\n",
    "\n",
    "seq32 = iaa.Sequential(\n",
    "    [\n",
    "        #\n",
    "        # Apply the following augmenters to most images.\n",
    "        #\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "\n",
    "        # crop some of the images by 0-10% of their height/width\n",
    "        sometimes(iaa.Crop(percent=(0, 0.1))),\n",
    "\n",
    "        # Apply affine transformations to some of the images\n",
    "        # - scale to 80-120% of image height/width (each axis independently)\n",
    "        # - translate by -20 to +20 relative to height/width (per axis)\n",
    "        # - rotate by -45 to +45 degrees\n",
    "        # - shear by -16 to +16 degrees\n",
    "        # - order: use nearest neighbour or bilinear interpolation (fast)\n",
    "        # - mode: use any available mode to fill newly created pixels\n",
    "        #         see API or scikit-image for which modes are available\n",
    "        # - cval: if the mode is constant, then use a random brightness\n",
    "        #         for the newly created pixels (e.g. sometimes black,\n",
    "        #         sometimes white)\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.625, 1), \"y\": (0.625, 1)},\n",
    "            translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "            rotate=(-20, 20),\n",
    "            shear=(-4, 4),\n",
    "            order=[0, 1],\n",
    "            cval=(0, 255),\n",
    "            mode=ia.ALL\n",
    "        )),\n",
    "\n",
    "        #\n",
    "        # Execute 0 to 5 of the following (less important) augmenters per\n",
    "        # image. Don't execute all of them, as that would often be way too\n",
    "        # strong.\n",
    "        #\n",
    "        iaa.SomeOf((0, 4),\n",
    "            [\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)),\n",
    "                    iaa.AverageBlur(k=(2, 7)),\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
    "                sometimes(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                    iaa.DirectedEdgeDetect(\n",
    "                        alpha=(0, 0.7), direction=(0.0, 1.0)\n",
    "                    ),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(\n",
    "                    loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n",
    "                ),\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5),\n",
    "                    iaa.CoarseDropout(\n",
    "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                        per_channel=0.2\n",
    "                    ),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), \n",
    "                iaa.Add((-10, 10), per_channel=0.5),\n",
    "                iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
    "                sometimes(\n",
    "                    iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)\n",
    "                ),\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05)))            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    # do all of the above augmentations in random order\n",
    "    random_order=True\n",
    ")\n",
    "\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        #\n",
    "        # Apply the following augmenters to most images.\n",
    "        #\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "\n",
    "        # crop some of the images by 0-10% of their height/width\n",
    "        sometimes(iaa.Crop(percent=(0, 0.1))),\n",
    "\n",
    "        # Apply affine transformations to some of the images\n",
    "        # - scale to 80-120% of image height/width (each axis independently)\n",
    "        # - translate by -20 to +20 relative to height/width (per axis)\n",
    "        # - rotate by -45 to +45 degrees\n",
    "        # - shear by -16 to +16 degrees\n",
    "        # - order: use nearest neighbour or bilinear interpolation (fast)\n",
    "        # - mode: use any available mode to fill newly created pixels\n",
    "        #         see API or scikit-image for which modes are available\n",
    "        # - cval: if the mode is constant, then use a random brightness\n",
    "        #         for the newly created pixels (e.g. sometimes black,\n",
    "        #         sometimes white)\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.6, 1), \"y\": (0.6, 1)},\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "            rotate=(-20, 20),\n",
    "            shear=(-8, 8),\n",
    "            order=[0, 1],\n",
    "            cval=(0, 255),\n",
    "            mode=ia.ALL\n",
    "        )),\n",
    "\n",
    "        #\n",
    "        # Execute 0 to 5 of the following (less important) augmenters per\n",
    "        # image. Don't execute all of them, as that would often be way too\n",
    "        # strong.\n",
    "        #\n",
    "        iaa.SomeOf((0, 5),\n",
    "            [\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)),\n",
    "                    iaa.AverageBlur(k=(2, 7)),\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)),\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)),\n",
    "                sometimes(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0, 0.7)),\n",
    "                    iaa.DirectedEdgeDetect(\n",
    "                        alpha=(0, 0.7), direction=(0.0, 1.0)\n",
    "                    ),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(\n",
    "                    loc=0, scale=(0.0, 0.05*255), per_channel=0.5\n",
    "                ),\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5),\n",
    "                    iaa.CoarseDropout(\n",
    "                        (0.03, 0.15), size_percent=(0.02, 0.05),\n",
    "                        per_channel=0.2\n",
    "                    ),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), \n",
    "                iaa.Add((-10, 10), per_channel=0.5),\n",
    "                iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5),\n",
    "                sometimes(\n",
    "                    iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)\n",
    "                ),\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05)))            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    # do all of the above augmentations in random order\n",
    "    random_order=True\n",
    ")\n",
    "\n",
    "def save_to_drive(drive, epoch, filename):  \n",
    "  title = 'Imagenetvd' + str(epoch) + '.hdf5'\n",
    "  model_file = drive.CreateFile({'title' : title})\n",
    "  model_file.SetContentFile(filename)\n",
    "  model_file.Upload()\n",
    "  print(\"Saving to id\", model_file.get('id'))\n",
    "  # download to google drive\n",
    "  drive.CreateFile({'id': model_file.get('id')})    \n",
    "  \n",
    "  \n",
    "def get_from_drive(idv):\n",
    "  global model_file\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)\n",
    "  last_weight_file = drive.CreateFile({'id': idv}) \n",
    "  last_weight_file.GetContentFile(model_file)    \n",
    "  \n",
    "class EarlyStoppingByAccuracy(Callback):\n",
    "    def __init__(self, monitor='val_acc', mode='max', value=0.98, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        global model_file\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "        print(\"Current learning rate\", k.get_value(self.model.optimizer.lr), k.get_value(self.model.optimizer.iterations)) \n",
    "        self.model.save(model_file, overwrite=True)\n",
    "        epoch = int((k.get_value(self.model.optimizer.iterations))/(int(NUM_IMAGES/BATCH_SIZE)))\n",
    "        #if(epoch%5==0):\n",
    "        drive = drive_authenticate()\n",
    "        save_to_drive(drive, epoch, model_file)\n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True, featurewise_std_normalization=True,\n",
    "    preprocessing_function=seq32.augment_image) \n",
    "train_datagen.mean = np.array([0.480337294172018, 0.44825522891986064, 0.39783786137898763], dtype=np.float32).reshape((1,1,3))\n",
    "train_datagen.std = np.array([0.27676311280482857, 0.26885390556775607, 0.28181860401080205], dtype=np.float32).reshape((1,1,3))\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True, featurewise_std_normalization=True,\n",
    "    shear_range = 0, # random application of shearing\n",
    "    zoom_range = 0,\n",
    "    horizontal_flip = False) \n",
    "valid_datagen.mean = np.array([0.480337294172018, 0.44825522891986064, 0.39783786137898763], dtype=np.float32).reshape((1,1,3))\n",
    "valid_datagen.std = np.array([0.27676311280482857, 0.26885390556775607, 0.28181860401080205], dtype=np.float32).reshape((1,1,3))\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAINING_IMAGES_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=(IMAGE_SIZE_T, IMAGE_SIZE_T),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "val_generator = valid_datagen.flow_from_directory(\n",
    "    directory=VAL_IMAGES_DIR,\n",
    "    target_size=(IMAGE_SIZE_T, IMAGE_SIZE_T),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size \n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n",
    "                                    cooldown=0, patience=5, min_lr=0.0000001)\n",
    "model_checkpoint= ModelCheckpoint(model_file, monitor=\"val_acc\", save_best_only=False,\n",
    "                                  verbose=1)\n",
    "early_stopping = EarlyStoppingByAccuracy(monitor='val_acc', value=0.70, verbose=1)\n",
    "csv_logger = CSVLogger('resnet50_imagenet200.csv')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dryNSKqP3qRv"
   },
   "outputs": [],
   "source": [
    "def bn_relu_conv(block, num_filter, conv_size):\n",
    "  block = BatchNormalization(epsilon=1.1e-5)(block)\n",
    "  block = Activation('relu')(block)\n",
    "  block = SeparableConv2D(num_filter, conv_size, use_bias=False, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(block)  \n",
    "  return block\n",
    "\n",
    "def add_denseblock(input, num_filter, out_filter):\n",
    "  temp = input\n",
    "  for _ in range(3):        \n",
    "      block = bn_relu_conv(temp, num_filter, (3, 3))\n",
    "      concat = Concatenate(axis=-1)([temp,block])\n",
    "      temp = concat\n",
    "      out_filter += num_filter\n",
    "\n",
    "  return temp, out_filter\n",
    "\n",
    "def add_transition(input, num_filter, pool=False):\n",
    "  block = bn_relu_conv(input, num_filter, (1, 1))\n",
    "  if pool:\n",
    "    block = AveragePooling2D(pool_size=(2,2))(block)    \n",
    "  return block, num_filter\n",
    "\n",
    "def output_layer(input):\n",
    "  block = bn_relu_conv(input, NUM_CLASSES, (1, 1))\n",
    "  block = BatchNormalization()(block)\n",
    "  block = Activation('relu')(block)\n",
    "  block = GlobalAveragePooling2D()(block)\n",
    "  output = Softmax(NUM_CLASSES)(block)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQND6issBo-t"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def space_to_depth_2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)\n",
    "  \n",
    "def space_to_depth_4(x):\n",
    "    return tf.space_to_depth(x, block_size=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVtjAdI63sC1"
   },
   "outputs": [],
   "source": [
    "def densenet(num_filter=32):\n",
    "  block = Conv2D(int(num_filter/2), (3,3), use_bias=False ,padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0001))(input)\n",
    "  block1, out1 = add_denseblock(block, num_filter, num_filter*2)\n",
    "  block1, out1 = add_transition(block1, out1)\n",
    "  block2, out2 = add_denseblock(block1, num_filter, out1)\n",
    "  block2, out2 = add_transition(block2, out2)\n",
    "  block3, out3 = add_denseblock(block2, num_filter, out2)\n",
    "  block3, out3 = add_transition(block3, out3, pool=True)\n",
    "  block4, out4 = add_denseblock(block3, num_filter, out3)\n",
    "  block4, out4 = add_transition(block4, out4, pool=True)\n",
    "  c1 = bn_relu_conv(block2, 64, (1,1))\n",
    "  c1 = Lambda(space_to_depth_4)(c1)\n",
    "  c2 = bn_relu_conv(block3, 256, (1,1))\n",
    "  c2 = Lambda(space_to_depth_2)(c2)\n",
    "  block = Concatenate(axis=-1)([c1,c2,block4])\n",
    "  block = bn_relu_conv(block, NUM_CLASSES*8, (1,1))\n",
    "  block = bn_relu_conv(block, NUM_CLASSES*4, (3,3))  \n",
    "  block = bn_relu_conv(block, NUM_CLASSES*2, (3,3))    \n",
    "  output = output_layer(block)    \n",
    "  model = Model(inputs=[input], outputs=[output])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3360
    },
    "colab_type": "code",
    "id": "AX5-NpZC3vRB",
    "outputId": "80393c89-b2c5-4b2a-a08f-db8c8d85036d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 3 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 3 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 3 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_23 (SeparableC (None, None, None, 6 2336        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, None, None, 9 0           conv2d_2[0][0]                   \n",
      "                                                                 separable_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 9 384         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_24 (SeparableC (None, None, None, 6 7008        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, None, None, 1 0           concatenate_14[0][0]             \n",
      "                                                                 separable_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 1 640         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 1 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_25 (SeparableC (None, None, None, 6 11680       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, None, None, 2 0           concatenate_15[0][0]             \n",
      "                                                                 separable_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 2 896         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 2 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_26 (SeparableC (None, None, None, 3 71904       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 3 1280        separable_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 3 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_27 (SeparableC (None, None, None, 6 23360       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, None, None, 3 0           separable_conv2d_26[0][0]        \n",
      "                                                                 separable_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 3 1536        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 3 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_28 (SeparableC (None, None, None, 6 28032       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, None, None, 4 0           concatenate_17[0][0]             \n",
      "                                                                 separable_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 4 1792        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 4 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_29 (SeparableC (None, None, None, 6 32704       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, None, None, 5 0           concatenate_18[0][0]             \n",
      "                                                                 separable_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 5 2048        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 5 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_30 (SeparableC (None, None, None, 5 262656      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 5 2048        separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 5 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_31 (SeparableC (None, None, None, 6 37376       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, None, None, 5 0           separable_conv2d_30[0][0]        \n",
      "                                                                 separable_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 5 2304        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 5 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_32 (SeparableC (None, None, None, 6 42048       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, None, None, 6 0           concatenate_20[0][0]             \n",
      "                                                                 separable_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 6 2560        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 6 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_33 (SeparableC (None, None, None, 6 46720       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, None, None, 7 0           concatenate_21[0][0]             \n",
      "                                                                 separable_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 7 2816        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 7 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_34 (SeparableC (None, None, None, 7 496320      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 7 0           separable_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 7 2816        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 7 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_35 (SeparableC (None, None, None, 6 51392       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, None, None, 7 0           average_pooling2d_3[0][0]        \n",
      "                                                                 separable_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 7 3072        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 7 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_36 (SeparableC (None, None, None, 6 56064       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, None, None, 8 0           concatenate_23[0][0]             \n",
      "                                                                 separable_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 8 3328        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 8 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_37 (SeparableC (None, None, None, 6 60736       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, None, None, 8 0           concatenate_24[0][0]             \n",
      "                                                                 separable_conv2d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 5 2048        separable_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 7 2816        average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 8 3584        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 5 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 7 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 8 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_39 (SeparableC (None, None, None, 6 33280       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_40 (SeparableC (None, None, None, 2 180928      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_38 (SeparableC (None, None, None, 8 803712      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, None, 1 0           separable_conv2d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None, None, 1 0           separable_conv2d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 8 0           separable_conv2d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, None, None, 2 0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 2 11776       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 2 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_41 (SeparableC (None, None, None, 1 4713344     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 6400        separable_conv2d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_42 (SeparableC (None, None, None, 8 1294400     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 8 3200        separable_conv2d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 8 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_43 (SeparableC (None, None, None, 4 327200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 4 1600        separable_conv2d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 4 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_44 (SeparableC (None, None, None, 2 80400       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 2 800         separable_conv2d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 2 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 200)          0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)             (None, 200)          0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 8,724,336\n",
      "Trainable params: 8,694,400\n",
      "Non-trainable params: 29,936\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.advanced_activations import Softmax\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation, GlobalAveragePooling2D, SeparableConv2D\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "input = Input(shape=(None, None, NUM_CHANNELS,))\n",
    "model = densenet(num_filter=64)\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1254
    },
    "colab_type": "code",
    "id": "egp1Echg3xUA",
    "outputId": "4e7b9a8a-b66c-45e2-ebfe-f721ac7ebe33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1562/1562 [==============================] - 1592s 1s/step - loss: 4.8105 - acc: 0.0605 - val_loss: 4.3155 - val_acc: 0.1087\n",
      "Current learning rate 0.001 1562\n",
      "\n",
      "Epoch 00001: saving model to Imagenetvd.hdf5\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - 1580s 1s/step - loss: 4.2235 - acc: 0.1411 - val_loss: 3.8027 - val_acc: 0.1886\n",
      "Current learning rate 0.001 3124\n",
      "\n",
      "Epoch 00002: saving model to Imagenetvd.hdf5\n",
      "Epoch 3/50\n",
      "1562/1562 [==============================] - 1576s 1s/step - loss: 3.8336 - acc: 0.1946 - val_loss: 3.4333 - val_acc: 0.2470\n",
      "Current learning rate 0.001 4686\n",
      "\n",
      "Epoch 00003: saving model to Imagenetvd.hdf5\n",
      "Epoch 4/50\n",
      "1562/1562 [==============================] - 1577s 1s/step - loss: 3.5559 - acc: 0.2360 - val_loss: 3.2340 - val_acc: 0.2766\n",
      "Current learning rate 0.001 6248\n",
      "\n",
      "Epoch 00004: saving model to Imagenetvd.hdf5\n",
      "Epoch 5/50\n",
      "1562/1562 [==============================] - 1578s 1s/step - loss: 3.3554 - acc: 0.2684 - val_loss: 3.1185 - val_acc: 0.3032\n",
      "Current learning rate 0.001 7810\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8995983aa53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-759c6555ecca>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_IMAGES\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m           \u001b[0mdrive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive_authenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m           \u001b[0msave_to_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drive_authenticate' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=NUM_EPOCHS, verbose=1,\n",
    "                    callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1260
    },
    "colab_type": "code",
    "id": "Pz6okkTLogxI",
    "outputId": "4f4aad10-ad25-4635-bfca-469dada172e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "1562/1562 [==============================] - 1587s 1s/step - loss: 3.1948 - acc: 0.2952 - val_loss: 2.9732 - val_acc: 0.3278\n",
      "Current learning rate 0.001 9372\n",
      "\n",
      "Epoch 00006: saving model to Imagenetvd.hdf5\n",
      "Epoch 7/50\n",
      "1562/1562 [==============================] - 1585s 1s/step - loss: 3.0575 - acc: 0.3168 - val_loss: 2.7520 - val_acc: 0.3686\n",
      "Current learning rate 0.001 10934\n",
      "\n",
      "Epoch 00007: saving model to Imagenetvd.hdf5\n",
      "Epoch 8/50\n",
      "1562/1562 [==============================] - 1581s 1s/step - loss: 2.9428 - acc: 0.3387 - val_loss: 2.6633 - val_acc: 0.3871\n",
      "Current learning rate 0.001 12496\n",
      "\n",
      "Epoch 00008: saving model to Imagenetvd.hdf5\n",
      "Epoch 9/50\n",
      "1562/1562 [==============================] - 1579s 1s/step - loss: 2.8363 - acc: 0.3583 - val_loss: 2.7351 - val_acc: 0.3737\n",
      "Current learning rate 0.001 14058\n",
      "\n",
      "Epoch 00009: saving model to Imagenetvd.hdf5\n",
      "Epoch 10/50\n",
      "1562/1562 [==============================] - 1575s 1s/step - loss: 2.7361 - acc: 0.3767 - val_loss: 2.6234 - val_acc: 0.3937\n",
      "Current learning rate 0.001 15620\n",
      "Saving to id 1RcSoWtoolBgk-U8z7upzFUeP5KT8v3d5\n",
      "\n",
      "Epoch 00010: saving model to Imagenetvd.hdf5\n",
      "Epoch 11/50\n",
      "1562/1562 [==============================] - 1577s 1s/step - loss: 2.6561 - acc: 0.3922 - val_loss: 2.5113 - val_acc: 0.4150\n",
      "Current learning rate 0.001 17182\n",
      "\n",
      "Epoch 00011: saving model to Imagenetvd.hdf5\n",
      "Epoch 12/50\n",
      "1562/1562 [==============================] - 1574s 1s/step - loss: 2.5775 - acc: 0.4067 - val_loss: 2.4428 - val_acc: 0.4308\n",
      "Current learning rate 0.001 18744\n",
      "\n",
      "Epoch 00012: saving model to Imagenetvd.hdf5\n",
      "Epoch 13/50\n",
      "1562/1562 [==============================] - 1575s 1s/step - loss: 2.5041 - acc: 0.4196 - val_loss: 2.4277 - val_acc: 0.4355\n",
      "Current learning rate 0.001 20306\n",
      "\n",
      "Epoch 00013: saving model to Imagenetvd.hdf5\n",
      "Epoch 14/50\n",
      "1562/1562 [==============================] - 1573s 1s/step - loss: 2.4260 - acc: 0.4355 - val_loss: 2.4518 - val_acc: 0.4330\n",
      "Current learning rate 0.001 21868\n",
      "\n",
      "Epoch 00014: saving model to Imagenetvd.hdf5\n",
      "Epoch 15/50\n",
      "1562/1562 [==============================] - 1564s 1s/step - loss: 2.3595 - acc: 0.4479 - val_loss: 2.3932 - val_acc: 0.4416\n",
      "Current learning rate 0.001 23430\n",
      "Saving to id 1xd_cUTGNRavpjYFrmin52dEXyO23UQIm\n",
      "\n",
      "Epoch 00015: saving model to Imagenetvd.hdf5\n",
      "Epoch 16/50\n",
      "1562/1562 [==============================] - 1560s 999ms/step - loss: 2.2924 - acc: 0.4622 - val_loss: 2.3120 - val_acc: 0.4578\n",
      "Current learning rate 0.001 24992\n",
      "\n",
      "Epoch 00016: saving model to Imagenetvd.hdf5\n",
      "Epoch 17/50\n",
      "1562/1562 [==============================] - 1559s 998ms/step - loss: 2.2273 - acc: 0.4755 - val_loss: 2.3026 - val_acc: 0.4611\n",
      "Current learning rate 0.001 26554\n",
      "\n",
      "Epoch 00017: saving model to Imagenetvd.hdf5\n",
      "Epoch 18/50\n",
      "1562/1562 [==============================] - 1559s 998ms/step - loss: 2.1666 - acc: 0.4878 - val_loss: 2.3460 - val_acc: 0.4541\n",
      "Current learning rate 0.001 28116\n",
      "\n",
      "Epoch 00018: saving model to Imagenetvd.hdf5\n",
      "Epoch 19/50\n",
      "1562/1562 [==============================] - 1559s 998ms/step - loss: 2.1177 - acc: 0.4952 - val_loss: 2.3441 - val_acc: 0.4584\n",
      "Current learning rate 0.001 29678\n",
      "\n",
      "Epoch 00019: saving model to Imagenetvd.hdf5\n",
      "Epoch 20/50\n",
      "1500/1562 [===========================>..] - ETA: 1:00 - loss: 2.0555 - acc: 0.5098"
     ]
    }
   ],
   "source": [
    "model.fit_generator(initial_epoch=5,\n",
    "                    generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=NUM_EPOCHS, verbose=1,\n",
    "                    callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "lyXQliKeqWUw",
    "outputId": "da035c7b-9b09-461c-9c79-7fbbeb38a26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "!cp drive/'My Drive'/Imagenetvd15.hdf5 .\n",
    "model = load_model('Imagenetvd15.hdf5', custom_objects={\"tf\": tf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "XVS_GVIRI7Dg",
    "outputId": "8883860d-b4e3-4bd2-bc5c-aaee209c1ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "781/781 [==============================] - 1001s 1s/step - loss: 2.2861 - acc: 0.4626 - val_loss: 2.8079 - val_acc: 0.3857\n",
      "Current learning rate 0.001 25370\n",
      "\n",
      "Epoch 00016: saving model to Imagenetvd.hdf5\n",
      "Epoch 17/20\n",
      "781/781 [==============================] - 1007s 1s/step - loss: 2.5634 - acc: 0.4003 - val_loss: 2.6938 - val_acc: 0.3931\n",
      "Current learning rate 0.001 26151\n",
      "\n",
      "Epoch 00017: saving model to Imagenetvd.hdf5\n",
      "Epoch 18/20\n",
      "781/781 [==============================] - 998s 1s/step - loss: 2.4797 - acc: 0.4150 - val_loss: 2.6603 - val_acc: 0.3956\n",
      "Current learning rate 0.001 26932\n",
      "\n",
      "Epoch 00018: saving model to Imagenetvd.hdf5\n",
      "Epoch 19/20\n",
      "781/781 [==============================] - 1003s 1s/step - loss: 2.4064 - acc: 0.4307 - val_loss: 2.6281 - val_acc: 0.4009\n",
      "Current learning rate 0.001 27713\n",
      "Saving to id 1IGJWcVW-iiEjZzKaz4Y0rfK_2o9gW4Dt\n",
      "\n",
      "Epoch 00019: saving model to Imagenetvd.hdf5\n",
      "Epoch 20/20\n",
      "781/781 [==============================] - 989s 1s/step - loss: 2.3469 - acc: 0.4427 - val_loss: 2.6095 - val_acc: 0.4119\n",
      "Current learning rate 0.001 28494\n",
      "\n",
      "Epoch 00020: saving model to Imagenetvd.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f131844c9e8>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loaded checkpoint from epoch 15, Training with 20x20\n",
    "model.fit_generator(initial_epoch=15,\n",
    "                    generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20, verbose=1,\n",
    "                    callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UayVzRr2mwP3"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "!cp drive/'My Drive'/Imagenetvd20.hdf5 .\n",
    "model = load_model('Imagenetvd20.hdf5', custom_objects={\"tf\": tf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "lnDLHABGJ2Rf",
    "outputId": "c9c8745e-ef41-4070-ecae-ccdcf9e44cb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/22\n",
      "1562/1562 [==============================] - 1553s 994ms/step - loss: 2.7223 - acc: 0.3797 - val_loss: 2.3829 - val_acc: 0.4442\n",
      "Current learning rate 0.001 30140\n",
      "\n",
      "Epoch 00021: saving model to Imagenetvd.hdf5\n",
      "Epoch 22/22\n",
      "1562/1562 [==============================] - 1563s 1s/step - loss: 2.6052 - acc: 0.4011 - val_loss: 2.3326 - val_acc: 0.4622\n",
      "Current learning rate 0.001 31702\n",
      "Saving to id 1Jn3aYMi7JlFesaJ01RqDcNRhcmhf6Mph\n",
      "\n",
      "Epoch 00022: saving model to Imagenetvd.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d047cbb70>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training on 32x32\n",
    "model.fit_generator(initial_epoch=20,\n",
    "                    generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=22, verbose=1,\n",
    "                    callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "1KdJi7v4mPqf",
    "outputId": "a4aca2d6-0f22-431d-861f-154b27d229a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n",
      "1562/1562 [==============================] - 1561s 1000ms/step - loss: 2.5498 - acc: 0.4108 - val_loss: 2.3393 - val_acc: 0.4516\n",
      "Current learning rate 0.001 33264\n",
      "\n",
      "Epoch 00023: saving model to Imagenetvd.hdf5\n",
      "Epoch 24/25\n",
      "1562/1562 [==============================] - 1555s 996ms/step - loss: 2.5113 - acc: 0.4195 - val_loss: 2.3512 - val_acc: 0.4597\n",
      "Current learning rate 0.001 34826\n",
      "\n",
      "Epoch 00024: saving model to Imagenetvd.hdf5\n",
      "Epoch 25/25\n",
      "1562/1562 [==============================] - 1555s 996ms/step - loss: 2.4594 - acc: 0.4290 - val_loss: 2.3073 - val_acc: 0.4688\n",
      "Current learning rate 0.001 36388\n",
      "\n",
      "Epoch 00025: saving model to Imagenetvd.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0cfe257940>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Continue training on 32x32\n",
    "model.fit_generator(initial_epoch=22,\n",
    "                    generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=25, verbose=1,\n",
    "                    callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1425
    },
    "colab_type": "code",
    "id": "ZNoGbVk-ZZ3O",
    "outputId": "27acc8f4-6256-43e5-9200-01e1f1a704ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1562/1562 [==============================] - 1562s 1000ms/step - loss: 2.4247 - acc: 0.4346 - val_loss: 2.2871 - val_acc: 0.4694\n",
      "Current learning rate 0.001 37950\n",
      "\n",
      "Epoch 00026: saving model to Imagenetvd.hdf5\n",
      "Epoch 27/30\n",
      "1562/1562 [==============================] - 1561s 999ms/step - loss: 2.3984 - acc: 0.4414 - val_loss: 2.3543 - val_acc: 0.4573\n",
      "Current learning rate 0.001 39512\n",
      "Saving to id 1xef3xGHlB6ID8LH1qSfKE_8YHyJndsxa\n",
      "\n",
      "Epoch 00027: saving model to Imagenetvd.hdf5\n",
      "Epoch 28/30\n",
      "1562/1562 [==============================] - 1555s 996ms/step - loss: 2.3463 - acc: 0.4510 - val_loss: 2.3317 - val_acc: 0.4690\n",
      "Current learning rate 0.001 41074\n",
      "\n",
      "Epoch 00028: saving model to Imagenetvd.hdf5\n",
      "Epoch 29/30\n",
      "1562/1562 [==============================] - 1541s 987ms/step - loss: 2.3159 - acc: 0.4582 - val_loss: 2.3071 - val_acc: 0.4666\n",
      "Current learning rate 0.001 42636\n",
      "\n",
      "Epoch 00029: saving model to Imagenetvd.hdf5\n",
      "Epoch 30/30\n",
      "  13/1562 [..............................] - ETA: 24:39 - loss: 2.1212 - acc: 0.5048"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8975543335a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Continue training on 32x32\n",
    "model.fit_generator(initial_epoch=25,\n",
    "                    generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=30, verbose=1,\n",
    "                    callbacks=[lr_reducer, early_stopping, csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w1yvKUCH0P6d",
    "outputId": "e13986d6-f19d-4244-d51f-11f519d32736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to id 1zgPu_qtl4VjInr9EdegDO4VryNNVs31d\n"
     ]
    }
   ],
   "source": [
    "drive = drive_authenticate()\n",
    "save_to_drive(drive, 29, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alXmwR-ae2aW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ImagenetDensenet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
